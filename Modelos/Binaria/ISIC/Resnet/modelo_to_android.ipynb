{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import fastbook\n",
    "import fastai\n",
    "import fastcore\n",
    "import PIL\n",
    "import shutil\n",
    "import albumentations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug as ia\n",
    "import seaborn as sns\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from fastai.vision.all import *\n",
    "from nbdev.showdoc import *\n",
    "from fastai.vision.all import *\n",
    "import torch.utils.mobile_optimizer as mobile_optimizer\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristhian/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1006: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    }
   ],
   "source": [
    "learn_inference = torch.load(\"bestISICFocal_512_32_50.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_module = torch.jit.script(learn_inference)\n",
    "optimized_scripted_module = optimize_for_mobile(scripted_module)\n",
    "\n",
    "# using optimized lite interpreter model makes inference about 60% faster than the non-optimized lite interpreter model, which is about 6% faster than the non-optimized full jit model\n",
    "scripted_module._save_for_lite_interpreter(\"my_model_lite.ptl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
