{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92485b90",
   "metadata": {},
   "source": [
    "# Evaluación de los modelos\n",
    "\n",
    "En este documento se muestran las pruebas realizadas para la evaluación del modelo mediante el conjunto de entrenamiento. Se pondrán a pruebas los modelos original y cuantizado de los 3 problemas de aprendizaje empleando la partición de test reservada antes del preprocesado de datos.\n",
    "\n",
    "## Resultados de test para clasificación binaria\n",
    "\n",
    "Se procede al cargado en memoria del modelo previamente entrenado para el entrenamiento habitual de escritorio. Es necesario importar el directorio de ficheros de entrenamiento para reconstruir el modelo, y posteriormente, realizar la inferencia de test. El flujo de código resultado es similar al entrenamiento, con la diferencia de que en lugar de optimizar el modelo, se procede directamente a la inferencia de los valores de test empleando los pesos ya entrenados.\n",
    "\n",
    "Otra opción de cargar el modelo sería utilizar el formato torchscript, pero en clasificación binaria, debido a la magnitud de los datos, es más favorecedor utilizar el objeto pth. Para la clasificación maligna y benigna, si se empleará este formato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d239d",
   "metadata": {},
   "source": [
    "Comenzamos por la importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T17:22:19.252116Z",
     "start_time": "2024-06-18T17:22:17.104524Z"
    }
   },
   "source": [
    "# Librerías utilizadas por el script\n",
    "\n",
    "import os\n",
    "#os.environ['HF_HOME'] = '/mnt/homeGPU/hexecode/cache/'\n",
    "\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import fastbook\n",
    "import fastai\n",
    "import fastcore\n",
    "import PIL\n",
    "import shutil\n",
    "import albumentations\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug as ia\n",
    "import seaborn as sns\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from fastai.vision.all import *\n",
    "from nbdev.showdoc import *\n",
    "from fastai.vision.all import *\n",
    "import torch.utils.mobile_optimizer as mobile_optimizer\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.models import resnet18\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "!pip install -Uqq fastbook\n",
    "!pip install nbdev\n",
    "\"\"\"\n",
    "fastbook.setup_book()\n",
    "torch.cuda.is_available()\n",
    "TEST_DIR = \"testThumbnails/\"\n",
    "test_metadata = pd.read_csv('testSet.csv')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modelo original\n",
    "Evaluamos el conjunto de test con el modelo original"
   ],
   "id": "29f8e3d18c80dd0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:22:19.255547Z",
     "start_time": "2024-06-18T17:22:19.252839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocesamiento (solo resize y normalización)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_imgs = test_metadata['image'].to_list()\n",
    "y_true = test_metadata['bin'].to_list()"
   ],
   "id": "ac7ba09229946eb2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:22:19.258585Z",
     "start_time": "2024-06-18T17:22:19.256321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_original(model, test_imgs):\n",
    "    y_pred = []\n",
    "    for img in test_imgs:\n",
    "        # Cargar imagen\n",
    "        image_path = TEST_DIR + img\n",
    "        image = Image.open(image_path)\n",
    "        input_tensor = transform(image).unsqueeze(0).cuda()\n",
    "\n",
    "        # Realiza la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "\n",
    "        # Indice con la mayor probabilidad\n",
    "        _, predicted_class = output.max(1)\n",
    "\n",
    "        y_pred.append(predicted_class.item())\n",
    "\n",
    "    return y_pred"
   ],
   "id": "829384295ffffb32",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.362757Z",
     "start_time": "2024-06-18T17:22:19.259319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargamos el modelo original\n",
    "model = torch.jit.load(\"bestISICFocal_512_32_50.pt\").to('cuda')\n",
    "y_pred = evaluate_original(model, test_imgs)"
   ],
   "id": "1638a66abd8abc16",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mostramos los resultados en un formato legible visible por el usuario.",
   "id": "5183acbbf2adb312"
  },
  {
   "cell_type": "code",
   "id": "9f23721f92bcec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.384414Z",
     "start_time": "2024-06-18T17:35:44.363318Z"
    }
   },
   "source": "print(classification_report(y_true, y_pred))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     16010\n",
      "           1       0.68      0.70      0.69      5468\n",
      "\n",
      "    accuracy                           0.84     21478\n",
      "   macro avg       0.79      0.80      0.79     21478\n",
      "weighted avg       0.84      0.84      0.84     21478\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora, repetimos el mismo proceso para el modelo adaptado para android. Realziaremos la evaluación con el modelo estándar sólo transformado al formato android, y el modelo cuantizado optimizado.",
   "id": "4406c6b693cc6ee4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modelo cuantizado",
   "id": "b92ca7c478ccb4af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.475045Z",
     "start_time": "2024-06-18T17:35:44.384865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Cargamos el modelo\n",
    "model_opt = torch.jit.load(\"bestISICFocal512_32_50_android.ptl\")"
   ],
   "id": "d42e0f1d008189dc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cargamos la lista de imágenes de test e iteramos por ellas, añadiendo la predicción al resultado.",
   "id": "6e07b710736d677f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.478342Z",
     "start_time": "2024-06-18T17:35:44.475870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_mobile(model, test_imgs):\n",
    "    y_pred = []\n",
    "    for img in test_imgs:\n",
    "        # Cargar imagen\n",
    "        image_path = TEST_DIR + img\n",
    "        image = Image.open(image_path)\n",
    "        input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "\n",
    "        # Realiza la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "\n",
    "\n",
    "        # Indice con la mayor probabilidad\n",
    "        _, predicted_class = output.max(1)\n",
    "\n",
    "        y_pred.append(predicted_class.item())\n",
    "\n",
    "    return y_pred"
   ],
   "id": "58186568620313f8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:07:32.926500Z",
     "start_time": "2024-06-18T17:35:44.479074Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred_mobile = evaluate_mobile(model_opt, test_imgs)",
   "id": "b27e00567e462ead",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:07:32.951359Z",
     "start_time": "2024-06-18T20:07:32.927134Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred_mobile))",
   "id": "acc1adbc1402beb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     16010\n",
      "           1       0.68      0.70      0.69      5468\n",
      "\n",
      "    accuracy                           0.84     21478\n",
      "   macro avg       0.79      0.80      0.79     21478\n",
      "weighted avg       0.84      0.84      0.84     21478\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para verificar en detalle el correcto funcionamiento del modelo, podemos emplear GradCam, y observar en qué puntos de la imagen se centra el modelo. Comenzaremos por una imagen correctamente clasificada.\n",
    "** NO DISPONIBLE PARA MODELO OPTIMIZADO O CUANTIZADO**"
   ],
   "id": "7c250ae3820ae02b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
