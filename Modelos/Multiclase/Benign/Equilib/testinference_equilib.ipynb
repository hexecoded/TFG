{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92485b90",
   "metadata": {},
   "source": [
    "# Evaluación de los modelos\n",
    "\n",
    "En este documento se muestran las pruebas realizadas para la evaluación del modelo mediante el conjunto de entrenamiento. Se pondrán a pruebas los modelos original y cuantizado de los 3 problemas de aprendizaje empleando la partición de test reservada antes del preprocesado de datos.\n",
    "\n",
    "## Resultados de test para clasificación binaria\n",
    "\n",
    "Se procede al cargado en memoria del modelo previamente entrenado para el entrenamiento habitual de escritorio. Es necesario importar el directorio de ficheros de entrenamiento para reconstruir el modelo, y posteriormente, realizar la inferencia de test. El flujo de código resultado es similar al entrenamiento, con la diferencia de que en lugar de optimizar el modelo, se procede directamente a la inferencia de los valores de test empleando los pesos ya entrenados.\n",
    "\n",
    "Otra opción de cargar el modelo sería utilizar el formato torchscript, pero en clasificación binaria, debido a la magnitud de los datos, es más favorecedor utilizar el objeto pth. Para la clasificación maligna y benigna, si se empleará este formato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d239d",
   "metadata": {},
   "source": [
    "Comenzamos por la importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T05:09:04.506056Z",
     "start_time": "2024-06-19T05:09:02.255260Z"
    }
   },
   "source": [
    "# Librerías utilizadas por el script\n",
    "\n",
    "import os\n",
    "#os.environ['HF_HOME'] = '/mnt/homeGPU/hexecode/cache/'\n",
    "\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import fastbook\n",
    "import fastai\n",
    "import fastcore\n",
    "import PIL\n",
    "import shutil\n",
    "import albumentations\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug as ia\n",
    "import seaborn as sns\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from fastai.vision.all import *\n",
    "from nbdev.showdoc import *\n",
    "from fastai.vision.all import *\n",
    "import torch.utils.mobile_optimizer as mobile_optimizer\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.models import resnet18\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "!pip install -Uqq fastbook\n",
    "!pip install nbdev\n",
    "\"\"\"\n",
    "fastbook.setup_book()\n",
    "torch.cuda.is_available()\n",
    "TEST_DIR = \"testThumbnails/\"\n",
    "test_metadata = pd.read_csv('testSet.csv')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.9 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Modelo original\n",
    "Evaluamos el conjunto de test con el modelo original"
   ],
   "id": "29f8e3d18c80dd0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:22:19.255547Z",
     "start_time": "2024-06-18T17:22:19.252839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocesamiento (solo resize y normalización)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_imgs = test_metadata['image'].to_list()\n",
    "y_true = test_metadata['bin'].to_list()"
   ],
   "id": "ac7ba09229946eb2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:28:00.869369Z",
     "start_time": "2024-06-19T05:28:00.867169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_original(model, test_imgs):\n",
    "    y_pred = []\n",
    "    for img in test_imgs:\n",
    "        # Cargar imagen\n",
    "        image_path = TEST_DIR + img\n",
    "        image = Image.open(image_path)\n",
    "        input_tensor = transform(image).unsqueeze(0).cuda()\n",
    "\n",
    "        # Realiza la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "\n",
    "        # Indice con la mayor probabilidad\n",
    "        _, predicted_class = output.max(1)\n",
    "\n",
    "        y_pred.append(predicted_class.item())\n",
    "\n",
    "    return y_pred"
   ],
   "id": "829384295ffffb32",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.362757Z",
     "start_time": "2024-06-18T17:22:19.259319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargamos el modelo original\n",
    "model = torch.jit.load(\"bestISICFocal_512_32_50.pt\").to('cuda')\n",
    "y_pred = evaluate_original(model, test_imgs)"
   ],
   "id": "1638a66abd8abc16",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mostramos los resultados en un formato legible visible por el usuario.",
   "id": "5183acbbf2adb312"
  },
  {
   "cell_type": "code",
   "id": "9f23721f92bcec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.384414Z",
     "start_time": "2024-06-18T17:35:44.363318Z"
    }
   },
   "source": "print(classification_report(y_true, y_pred))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     16010\n",
      "           1       0.68      0.70      0.69      5468\n",
      "\n",
      "    accuracy                           0.84     21478\n",
      "   macro avg       0.79      0.80      0.79     21478\n",
      "weighted avg       0.84      0.84      0.84     21478\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora, repetimos el mismo proceso para el modelo adaptado para android. Realziaremos la evaluación con el modelo estándar sólo transformado al formato android, y el modelo cuantizado optimizado.",
   "id": "4406c6b693cc6ee4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modelo cuantizado",
   "id": "b92ca7c478ccb4af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:35:44.475045Z",
     "start_time": "2024-06-18T17:35:44.384865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Cargamos el modelo\n",
    "model_opt = torch.jit.load(\"bestISICFocal512_32_50_android.ptl\")"
   ],
   "id": "d42e0f1d008189dc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cargamos la lista de imágenes de test e iteramos por ellas, añadiendo la predicción al resultado.",
   "id": "6e07b710736d677f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:31:12.377135Z",
     "start_time": "2024-06-19T05:31:12.374889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_mobile(model, test_imgs):\n",
    "    y_pred = []\n",
    "    for img in test_imgs:\n",
    "        # Cargar imagen\n",
    "        image_path = TEST_DIR + img\n",
    "        image = Image.open(image_path)\n",
    "        input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "        # Realiza la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "\n",
    "        # Indice con la mayor probabilidad\n",
    "        _, predicted_class = output.max(1)\n",
    "\n",
    "        y_pred.append(predicted_class.item())\n",
    "\n",
    "    return y_pred"
   ],
   "id": "58186568620313f8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:07:32.926500Z",
     "start_time": "2024-06-18T17:35:44.479074Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred_mobile = evaluate_mobile(model_opt, test_imgs)",
   "id": "b27e00567e462ead",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:07:32.951359Z",
     "start_time": "2024-06-18T20:07:32.927134Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred_mobile))",
   "id": "acc1adbc1402beb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     16010\n",
      "           1       0.68      0.70      0.69      5468\n",
      "\n",
      "    accuracy                           0.84     21478\n",
      "   macro avg       0.79      0.80      0.79     21478\n",
      "weighted avg       0.84      0.84      0.84     21478\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para verificar en detalle el correcto funcionamiento del modelo, podemos emplear GradCam, y observar en qué puntos de la imagen se centra el modelo. Comenzaremos por una imagen correctamente clasificada.\n",
    "** NO DISPONIBLE PARA MODELO OPTIMIZADO O CUANTIZADO**"
   ],
   "id": "7c250ae3820ae02b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9c4c96247359bc93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Resultados de test para clasificación multiclase\n",
    "\n",
    "Ahora, evaluaremos el rendimiento de los dos modelos de clasificación multiclase. Ambos modelos serán evaluados con la partición de test, extrayendo las clases oportunas, y aplicando el mismo tipo de preprocesado que al conjunto de entrenamiento."
   ],
   "id": "7327b86d3b42c5ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Modelo de clases malignas\n",
    "\n",
    "En este primer caso, estudiaremos el impacto en métricas del modelo original vs cuantizado en test, empleando unicamente imágenes malignas. Recordar que, en este modelo, debemos realizar el mismo preprocesado que en train, por lo que debemos:\n",
    "- Fusionar la clase melanoma y melanoma metastasis\n",
    "- Normalizar y redimensionar usando los parámetros de imagenet y resolución 512 x 512."
   ],
   "id": "459bd39ec6efa204"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Modelo original",
   "id": "877ab2de40fcf119"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_malignant = test_metadata.loc[test_metadata['bin'] == 1]\n",
    "train_malignant['label'].replace('melanoma_metastasis', 'melanoma', inplace=True)"
   ],
   "id": "e4769a779412826e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Renombramos a notación numérica\n",
    "replacements = {'basal_cell_carcinoma': 0, 'melanoma': 1, 'squamous_cell_carcinoma': 2}\n",
    "train_malignant['label'] = train_malignant['label'].map(replacements).fillna(train_malignant['label'])"
   ],
   "id": "752c7c34c63f15c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comprobamos que la transformación ha sido exitosa",
   "id": "8b493b66b5dff3d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:38:50.581430Z",
     "start_time": "2024-06-19T03:38:50.578276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_malignant['label'].unique())\n",
    "print(train_malignant.label.value_counts())\n",
    "y_true = train_malignant.label.to_list()\n",
    "test_malign_imgs = train_malignant.image.to_list()"
   ],
   "id": "b3ee538161977f1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n",
      "label\n",
      "1    2950\n",
      "0    1969\n",
      "2     549\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cargamos modelo original y realizamos inferncia",
   "id": "4c7eddfbd7e00d3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:38:50.616829Z",
     "start_time": "2024-06-19T03:38:50.614341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocesamiento (solo resize y normalización)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "id": "8b294eb21bc21681",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:41:58.862853Z",
     "start_time": "2024-06-19T03:38:50.618132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargamos el modelo original\n",
    "model = torch.jit.load(\"bestISICmalignant_512.pt\").to('cuda')\n",
    "y_pred = evaluate_original(model, test_malign_imgs)"
   ],
   "id": "1b181ac867d86033",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:41:58.871445Z",
     "start_time": "2024-06-19T03:41:58.863554Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred))",
   "id": "b8e19f0eee6ed2b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1969\n",
      "           1       0.87      0.92      0.89      2950\n",
      "           2       0.65      0.37      0.47       549\n",
      "\n",
      "    accuracy                           0.83      5468\n",
      "   macro avg       0.78      0.71      0.73      5468\n",
      "weighted avg       0.83      0.83      0.83      5468\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ba4d1936d1ce5f1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Modelo cuantizado",
   "id": "6ba12fa82da0398d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:41:58.913732Z",
     "start_time": "2024-06-19T03:41:58.871856Z"
    }
   },
   "cell_type": "code",
   "source": "model_opt = torch.jit.load(\"bestISICmalignant 512_android.ptl\")",
   "id": "5e11a7a0253ebee1",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:25:32.729641Z",
     "start_time": "2024-06-19T03:41:58.914794Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred = evaluate_mobile(model_opt, test_malign_imgs)",
   "id": "875750270cf5ee9c",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:25:32.739927Z",
     "start_time": "2024-06-19T04:25:32.730210Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred))",
   "id": "4b7e829e43855a6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1969\n",
      "           1       0.87      0.92      0.89      2950\n",
      "           2       0.65      0.37      0.47       549\n",
      "\n",
      "    accuracy                           0.83      5468\n",
      "   macro avg       0.78      0.71      0.73      5468\n",
      "weighted avg       0.82      0.83      0.82      5468\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Modelo de clases benignas\n",
    "\n",
    "Ahora, es el turno del modelo para imágenes benignas. El proceso es exactamente el mismo que el seguido para el subconjunto maligno, pero con bin = 1."
   ],
   "id": "875cf7bafc9ccf93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:19:58.774441Z",
     "start_time": "2024-06-19T05:19:58.771598Z"
    }
   },
   "cell_type": "code",
   "source": "train_benign = test_metadata.loc[test_metadata['bin'] == 0]",
   "id": "929596a3e39f7d16",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:20:00.494492Z",
     "start_time": "2024-06-19T05:20:00.491955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mostramos recuento para ver si la fusión se ha realizado correctamente.\n",
    "print(train_benign.label.value_counts())"
   ],
   "id": "9c3f9bec520e8dcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "nevus                                 13067\n",
      "seborreic_keratosis                     770\n",
      "actinic_keratosis                       547\n",
      "pigmented_benign_keratosis              536\n",
      "solar_lentigo                           225\n",
      "dermatofibroma                          168\n",
      "vascular_lesion                         139\n",
      "lichenoid_keratosis                     125\n",
      "acrochordon                             120\n",
      "lentigo_nos                              96\n",
      "atypical_melanocytic_proliferation       56\n",
      "aimp                                     48\n",
      "wart                                     48\n",
      "angioma                                  28\n",
      "lentigo_simplex                          17\n",
      "scar                                     10\n",
      "neurofibroma                             10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Renombramos a notación numérica\n",
    "replacements = {\n",
    "    'nevus': 10,\n",
    "    'seborreic_keratosis': 13,\n",
    "    'actinic_keratosis': 1,\n",
    "    'pigmented_benign_keratosis': 11,\n",
    "    'solar_lentigo': 14,\n",
    "    'dermatofibroma': 5,\n",
    "    'vascular_lesion': 15,\n",
    "    'lichenoid_keratosis': 8,\n",
    "    'acrochordon': 0,\n",
    "    'lentigo_nos': 6,\n",
    "    'atypical_melanocytic_proliferation': 2,\n",
    "    'aimp': 4,\n",
    "    'wart': 16,\n",
    "    'angioma': 3,\n",
    "    'lentigo_simplex': 7,\n",
    "    'scar': 9,\n",
    "    'neurofibroma': 12\n",
    "}\n",
    "\n",
    "train_benign['label'] = train_benign['label'].map(replacements).fillna(train_benign['label'])"
   ],
   "id": "102da33fe86bd0d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:34:48.291375Z",
     "start_time": "2024-06-19T05:34:48.287913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_benign.label.value_counts())\n",
    "y_true = train_benign.label.to_list()\n",
    "test_benign_imgs = train_benign.image.to_list()"
   ],
   "id": "201ddb847d3bdd30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "10    13067\n",
      "13      770\n",
      "1       547\n",
      "11      536\n",
      "14      225\n",
      "5       168\n",
      "15      139\n",
      "8       125\n",
      "0       120\n",
      "6        96\n",
      "2        56\n",
      "4        48\n",
      "16       48\n",
      "3        28\n",
      "7        17\n",
      "9        10\n",
      "12       10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Modelo original",
   "id": "76401f6fb9dfcfce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:34:48.449950Z",
     "start_time": "2024-06-19T05:34:48.307571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocesamiento (solo resize y normalización)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Cargamos el modelo original\n",
    "model = torch.jit.load(\"bestISICbenign_512.pt\").to('cuda')"
   ],
   "id": "7aef4152ad699d31",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Realizamos las predicciones",
   "id": "32b171f5f247c051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:44:55.688357Z",
     "start_time": "2024-06-19T05:34:48.451152Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred = evaluate_original(model, test_benign_imgs)",
   "id": "55c0e20e771e7cc5",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mostramos los resultados",
   "id": "7c1dcef784a03745"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:44:55.705900Z",
     "start_time": "2024-06-19T05:44:55.688981Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred))",
   "id": "215c7a11c8f81763",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.72      0.42       120\n",
      "           1       0.53      0.59      0.56       547\n",
      "           2       0.04      0.07      0.05        56\n",
      "           3       0.35      0.50      0.41        28\n",
      "           4       0.02      0.08      0.03        48\n",
      "           5       0.28      0.61      0.38       168\n",
      "           6       0.11      0.36      0.17        96\n",
      "           7       0.19      0.53      0.28        17\n",
      "           8       0.20      0.43      0.27       125\n",
      "           9       0.00      0.00      0.00        10\n",
      "          10       0.99      0.78      0.87     13067\n",
      "          11       0.39      0.87      0.54       536\n",
      "          12       0.00      0.00      0.00        10\n",
      "          13       0.31      0.61      0.41       770\n",
      "          14       0.20      0.47      0.28       225\n",
      "          15       0.59      0.83      0.69       139\n",
      "          16       0.27      0.23      0.25        48\n",
      "\n",
      "    accuracy                           0.75     16010\n",
      "   macro avg       0.28      0.45      0.33     16010\n",
      "weighted avg       0.87      0.75      0.79     16010\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Modelo cuantizado",
   "id": "459deb34d1197dcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T05:44:55.749422Z",
     "start_time": "2024-06-19T05:44:55.706530Z"
    }
   },
   "cell_type": "code",
   "source": "model_opt = torch.jit.load(\"bestISICbenign512_android.ptl\")",
   "id": "bb3be7dad847180",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:42:39.759355Z",
     "start_time": "2024-06-19T05:44:55.750018Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred_mob = evaluate_mobile(model_opt, test_benign_imgs)",
   "id": "6337af5333b4ca99",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:42:39.808119Z",
     "start_time": "2024-06-19T07:42:39.767637Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred_mob))",
   "id": "af8ba277e799bbdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.72      0.42       120\n",
      "           1       0.53      0.59      0.56       547\n",
      "           2       0.04      0.07      0.05        56\n",
      "           3       0.35      0.50      0.41        28\n",
      "           4       0.02      0.08      0.03        48\n",
      "           5       0.27      0.61      0.38       168\n",
      "           6       0.11      0.36      0.17        96\n",
      "           7       0.19      0.53      0.28        17\n",
      "           8       0.21      0.45      0.28       125\n",
      "           9       0.00      0.00      0.00        10\n",
      "          10       0.99      0.78      0.87     13067\n",
      "          11       0.39      0.87      0.54       536\n",
      "          12       0.00      0.00      0.00        10\n",
      "          13       0.31      0.60      0.41       770\n",
      "          14       0.21      0.48      0.29       225\n",
      "          15       0.59      0.83      0.69       139\n",
      "          16       0.28      0.23      0.25        48\n",
      "\n",
      "    accuracy                           0.75     16010\n",
      "   macro avg       0.28      0.45      0.33     16010\n",
      "weighted avg       0.87      0.75      0.79     16010\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
