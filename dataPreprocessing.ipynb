{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocesado de datos\n",
    "\n",
    "El preprocesado de datos es una fase indispensable para el correndo aprendizaje por partes de los algoritmos de Deeplearning. Se ha demostrado empíricamente que una correcta preparación y normalización de los datos permiten hallar soluciones más cercanas a la optima que con datos no procesados.\n",
    "\n",
    "Es importante tener en cuenta que no existe una metodología de preprocesado única, y que es necesario adaptarse al tipo de dato que estamos tratando. Para este proyecto, además, existe una dificultad adicional, y es la existencia de diferentes procedencias para los datos, pues en total se dispone de 5 datasets distintos, cada uno recopilado con diferentes metodologías e instrumentación. Por tanto, será clave adaptarse a cada uno de los destinos, y realizar la partición final de forma estratificada para evitar sesgos que perturben el resutado.\n",
    "\n",
    "Más adelante, profundizaremos en este aspecto, pero en primer lugar, debemos leer cada uno de los conjuntos de datos disponibles, y examinar de cuántos elementos disponemos en cada uno, para establecer la proporción de entrenamiento-test oportuna."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785e9721acd8fc9b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Librerías utilizadas por el script\n",
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T01:41:41.569512Z",
     "start_time": "2024-03-30T01:41:41.564798Z"
    }
   },
   "id": "afde0d5870507596",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset disponibles\n",
    "\n",
    "Haciendo uso de los recursos disponibles públicamente, se han tomado los siguientes datasets para realizar el experimento:\n",
    "- ISIC: es el mayor conjuntos de datos cutáneos disponible en abierto, y contiene imágenes de todo tipo de pieles y procedencias, pero con especial énfasis en las personas de origen europeo y americano.\n",
    "- ASAN: Conjunto de datos provenientes del hospital con este mismo nombre, con lesiones en personas de origen asiático.\n",
    "- PAD UFES 20: conjunto de datos de lesiones variadas de pacientes latinoamericanos.\n",
    "- PH2: banco de datos de pacientes brasileños con lesiones potencialmente cancerosas.\n",
    "- Severance: base de datos con lesiones cutáneas en población asiática, con contenido tanto benigno como cancerígeno.\n",
    "\n",
    "Para unificar la notación de los datos, se creará un código para la notación de cada una de las clases que permitan un procesamiento común de todos los datos sin depender del origen de este. Para ello, se creará un nuevo archivo .csv donde se anotará el path de la imagen, su clase asociada, y el tipo general de la misma (beningna o maligna). La metainformación asociada, de momento, quedará relegado a un segundo plano hasta el estudio estadístico de los datos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f2cc21e905cd6fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Directorios de cada dataset\n",
    "\n",
    "ISIC_PATH = \"datasets/ISIC\"\n",
    "ASAN_PATH = \"datasets/ASAN\"\n",
    "PAD_UFES_PATH = \"datasets/PAD_UFES_20\"\n",
    "PH2_PATH = \"datasets/PH2\"\n",
    "SEVERANCE = \"datasets/Severance\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T01:43:58.593636Z",
     "start_time": "2024-03-30T01:43:58.589468Z"
    }
   },
   "id": "8181ac991513a205",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Funciones comunes para la lectura y muestra de datos\n",
    "\n",
    "'''\n",
    "This function receives a string with the filename of the image to read,\n",
    "and a flag indicating if we want to read it in color/RGB (flagColor=1) or gray level (flagColor=0)\n",
    "\n",
    "Example of use:\n",
    "im1=readIm(get_image('apple.jpg'),0)\n",
    "'''\n",
    "\n",
    "\n",
    "def readIm(filename, flagColor=1):\n",
    "    # cv2 reads BGR format\n",
    "    im = cv2.imread(filename)\n",
    "    # change to  RGB and return the image\n",
    "    if (flagColor):\n",
    "        return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    # change from BGR to grayscale instead if flag is 0\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "'''\n",
    "This function receives an array of arbitrary real numbers (that could include even negative values),\n",
    "and returns an 'image' in the range [0,1].\n",
    "flag_GLOBAL allows the user to normalize the whole image (including all channels) or to normalize\n",
    "each channel/band independently.\n",
    "'''\n",
    "\n",
    "\n",
    "def rangeDisplay01(im, flag_GLOBAL=True):\n",
    "    im = im.astype(float)\n",
    "    if flag_GLOBAL:\n",
    "        im = (im - im.min()) / (im.max() - im.min())\n",
    "    else:\n",
    "        # bands normalization\n",
    "        for band in range(im.shape[2]):\n",
    "            im[:, :, band] = (im[:, :, band] - im[:, :, band].min()) / (im[:, :, band].max() - im[:, :, band].min())\n",
    "            # Note: remember that, for plt.imshow with RGB data, the valid range is [0..1] for floats and [0..255] for integers.\n",
    "    return im\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Función para mostrar imágenes en pantalla en color y blanco negro. Permite realizar\n",
    "aumento sobre las mismas para apreciar un mayor detalle.\n",
    "\n",
    "Entrada:\n",
    "    im: imagen leída en formato ndarray\n",
    "    title: nombre que recibe el marco en pantalla\n",
    "    factor: factor de aumento de la image, \"zoom\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def displayIm(im, title='Result', factor=2):\n",
    "    # First normalize range\n",
    "    max = np.max(im)\n",
    "    min = np.min(im)\n",
    "    if min < 0 or max > 255:\n",
    "        im = rangeDisplay01(im, flag_GLOBAL=True)\n",
    "    if len(im.shape) == 3:\n",
    "        # im es tribanda\n",
    "        plt.imshow(im, cmap='jet')\n",
    "    else:\n",
    "        # im es monobanda\n",
    "        plt.imshow(im, cmap='gray')\n",
    "    figure_size = plt.gcf().get_size_inches()\n",
    "    plt.gcf().set_size_inches(factor * figure_size)\n",
    "    plt.title(title)\n",
    "    plt.xticks([]), plt.yticks([])  # eliminamos numeración\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T01:32:39.983940Z",
     "start_time": "2024-03-30T01:32:39.974347Z"
    }
   },
   "id": "3fc4a96b5083fb1e",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ISIC Skin Dataset\n",
    "\n",
    "Se trata del dataset de mayor tamaño del conjunto. Contiene 31 clases identificadas, tanto de lesiones benignas y malignas de la piel. En total, se dispone de 53738, las cuales ya han sido filtradas para asegurarse de que no exista redundancia por las herramientas online de la galería ISIC: https://gallery.isic-archive.com/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1408e12cf23be0cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extractISIC(path: str):\n",
    "    # Obtener una lista de todos los archivos ZIP en la carpeta especificada\n",
    "    archivos_zip = [f for f in os.listdir(path) if f.lower().endswith('.zip')]\n",
    "\n",
    "    # Iterar sobre cada archivo ZIP\n",
    "    for archivo_zip in archivos_zip:\n",
    "        ruta_archivo_zip = os.path.join(path, archivo_zip)\n",
    "        carpeta_salida = os.path.splitext(ruta_archivo_zip)[0]  # Eliminar la extensión .zip\n",
    "\n",
    "        # Comprobar si la carpeta de salida ya existe\n",
    "        if not os.path.exists(carpeta_salida):\n",
    "            os.makedirs(carpeta_salida)  # Crear la carpeta de salida\n",
    "\n",
    "            # Extraer el contenido del archivo ZIP en la carpeta de salida\n",
    "            with zipfile.ZipFile(ruta_archivo_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(carpeta_salida)\n",
    "            print(f\"Extraído {archivo_zip} en {carpeta_salida}\")\n",
    "        else:\n",
    "            print(f\"Omitido {archivo_zip}. {carpeta_salida} ya existe.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T01:44:46.528956Z",
     "start_time": "2024-03-30T01:44:46.523315Z"
    }
   },
   "id": "d41e691f663fb6eb",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "Extraído Acrochordon.zip en datasets/ISIC\\Acrochordon\n",
      "Extraído Acticnic keratosis.zip en datasets/ISIC\\Acticnic keratosis\n",
      "Extraído AIMP.zip en datasets/ISIC\\AIMP\n",
      "Extraído Angiofroma o fibreus papile.zip en datasets/ISIC\\Angiofroma o fibreus papile\n",
      "Extraído Angiokeratoma.zip en datasets/ISIC\\Angiokeratoma\n",
      "Extraído Angioma.zip en datasets/ISIC\\Angioma\n",
      "Extraído Atypical melatocynic proliferation.zip en datasets/ISIC\\Atypical melatocynic proliferation\n",
      "Extraído Atypical spitz tumor.zip en datasets/ISIC\\Atypical spitz tumor\n",
      "Extraído Basal Cell Carcinoma.zip en datasets/ISIC\\Basal Cell Carcinoma\n",
      "Extraído Cafe au lait macule.zip en datasets/ISIC\\Cafe au lait macule\n",
      "Extraído Clear cell acarthoma.zip en datasets/ISIC\\Clear cell acarthoma\n",
      "Extraído Dermatofibroma.zip en datasets/ISIC\\Dermatofibroma\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mgetcwd())\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Extraemos cada zip, en caso de que no exista\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m extractISIC(ISIC_PATH)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mgetcwd())\n",
      "Cell \u001B[1;32mIn[36], line 16\u001B[0m, in \u001B[0;36mextractISIC\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# Extraer el contenido del archivo ZIP en la carpeta de salida\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m zipfile\u001B[38;5;241m.\u001B[39mZipFile(ruta_archivo_zip, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m zip_ref:\n\u001B[1;32m---> 16\u001B[0m         zip_ref\u001B[38;5;241m.\u001B[39mextractall(carpeta_salida)\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtraído \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchivo_zip\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m en \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcarpeta_salida\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\zipfile.py:1681\u001B[0m, in \u001B[0;36mZipFile.extractall\u001B[1;34m(self, path, members, pwd)\u001B[0m\n\u001B[0;32m   1678\u001B[0m     path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(path)\n\u001B[0;32m   1680\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m zipinfo \u001B[38;5;129;01min\u001B[39;00m members:\n\u001B[1;32m-> 1681\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extract_member(zipinfo, path, pwd)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\zipfile.py:1736\u001B[0m, in \u001B[0;36mZipFile._extract_member\u001B[1;34m(self, member, targetpath, pwd)\u001B[0m\n\u001B[0;32m   1732\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m targetpath\n\u001B[0;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopen(member, pwd\u001B[38;5;241m=\u001B[39mpwd) \u001B[38;5;28;01mas\u001B[39;00m source, \\\n\u001B[0;32m   1735\u001B[0m      \u001B[38;5;28mopen\u001B[39m(targetpath, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m target:\n\u001B[1;32m-> 1736\u001B[0m     shutil\u001B[38;5;241m.\u001B[39mcopyfileobj(source, target)\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m targetpath\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\shutil.py:197\u001B[0m, in \u001B[0;36mcopyfileobj\u001B[1;34m(fsrc, fdst, length)\u001B[0m\n\u001B[0;32m    195\u001B[0m fdst_write \u001B[38;5;241m=\u001B[39m fdst\u001B[38;5;241m.\u001B[39mwrite\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 197\u001B[0m     buf \u001B[38;5;241m=\u001B[39m fsrc_read(length)\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m buf:\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\zipfile.py:955\u001B[0m, in \u001B[0;36mZipExtFile.read\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eof:\n\u001B[1;32m--> 955\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read1(n)\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(data):\n\u001B[0;32m    957\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_readbuffer \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\zipfile.py:1025\u001B[0m, in \u001B[0;36mZipExtFile._read1\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1023\u001B[0m         data \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read2(n \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(data))\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1025\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read2(n)\n\u001B[0;32m   1027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_type \u001B[38;5;241m==\u001B[39m ZIP_STORED:\n\u001B[0;32m   1028\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eof \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_left \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\zipfile.py:1055\u001B[0m, in \u001B[0;36mZipExtFile._read2\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1052\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(n, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMIN_READ_SIZE)\n\u001B[0;32m   1053\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(n, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_left)\n\u001B[1;32m-> 1055\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fileobj\u001B[38;5;241m.\u001B[39mread(n)\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_left \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(data)\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\zipfile.py:775\u001B[0m, in \u001B[0;36m_SharedFile.read\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m    771\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt read from the ZIP file while there \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    772\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis an open writing handle on it. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    773\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClose the writing handle before trying to read.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    774\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos)\n\u001B[1;32m--> 775\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file\u001B[38;5;241m.\u001B[39mread(n)\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Accedemos al directorio de ISIC\n",
    "print(os.getcwd())\n",
    "\n",
    "# Extraemos cada zip, en caso de que no exista\n",
    "extractISIC(ISIC_PATH)\n",
    "\n",
    "print(os.getcwd())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T01:45:32.439818Z",
     "start_time": "2024-03-30T01:44:47.822330Z"
    }
   },
   "id": "30e522877d106585",
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
