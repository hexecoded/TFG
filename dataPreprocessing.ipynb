{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocesado de datos\n",
    "\n",
    "El preprocesado de datos es una fase indispensable para el correndo aprendizaje por partes de los algoritmos de Deeplearning. Se ha demostrado empíricamente que una correcta preparación y normalización de los datos permiten hallar soluciones más cercanas a la optima que con datos no procesados.\n",
    "\n",
    "Es importante tener en cuenta que no existe una metodología de preprocesado única, y que es necesario adaptarse al tipo de dato que estamos tratando. Para este proyecto, además, existe una dificultad adicional, y es la existencia de diferentes procedencias para los datos, pues en total se dispone de 5 datasets distintos, cada uno recopilado con diferentes metodologías e instrumentación. Por tanto, será clave adaptarse a cada uno de los destinos, y realizar la partición final de forma estratificada para evitar sesgos que perturben el resutado.\n",
    "\n",
    "Más adelante, profundizaremos en este aspecto, pero en primer lugar, debemos leer cada uno de los conjuntos de datos disponibles, y examinar de cuántos elementos disponemos en cada uno, para establecer la proporción de entrenamiento-test oportuna."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785e9721acd8fc9b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Librerías utilizadas por el script\n",
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "import csv\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:33:45.591419Z",
     "start_time": "2024-03-30T13:33:45.382010Z"
    }
   },
   "id": "afde0d5870507596",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset disponibles\n",
    "\n",
    "Haciendo uso de los recursos disponibles públicamente, se han tomado los siguientes datasets para realizar el experimento:\n",
    "- ISIC: es el mayor conjuntos de datos cutáneos disponible en abierto, y contiene imágenes de todo tipo de pieles y procedencias, pero con especial énfasis en las personas de origen europeo y americano.\n",
    "- ASAN: Conjunto de datos provenientes del hospital con este mismo nombre, con lesiones en personas de origen asiático.\n",
    "- PAD UFES 20: conjunto de datos de lesiones variadas de pacientes latinoamericanos.\n",
    "- PH2: banco de datos de pacientes brasileños con lesiones potencialmente cancerosas.\n",
    "- Severance: base de datos con lesiones cutáneas en población asiática, con contenido tanto benigno como cancerígeno.\n",
    "\n",
    "Para unificar la notación de los datos, se creará un código para la notación de cada una de las clases que permitan un procesamiento común de todos los datos sin depender del origen de este. Para ello, se creará un nuevo archivo .csv donde se anotará el path de la imagen, su clase asociada, y el tipo general de la misma (beningna o maligna). La metainformación asociada, de momento, quedará relegado a un segundo plano hasta el estudio estadístico de los datos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f2cc21e905cd6fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Directorios de cada dataset\n",
    "\n",
    "ISIC_PATH = \"datasets/ISIC\"\n",
    "ASAN_PATH = \"datasets/Asan\"\n",
    "PAD_UFES_PATH = \"datasets/PAD_UFES_20\"\n",
    "PH2_PATH = \"datasets/PH2\"\n",
    "SEVERANCE = \"datasets/Severance\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:33:45.597093Z",
     "start_time": "2024-03-30T13:33:45.593526Z"
    }
   },
   "id": "8181ac991513a205",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Funciones comunes para la lectura y muestra de datos\n",
    "\n",
    "'''\n",
    "This function receives a string with the filename of the image to read,\n",
    "and a flag indicating if we want to read it in color/RGB (flagColor=1) or gray level (flagColor=0)\n",
    "\n",
    "Example of use:\n",
    "im1=readIm(get_image('apple.jpg'),0)\n",
    "'''\n",
    "\n",
    "\n",
    "def readIm(filename, flagColor=1):\n",
    "    # cv2 reads BGR format\n",
    "    im = cv2.imread(filename)\n",
    "    # change to  RGB and return the image\n",
    "    if (flagColor):\n",
    "        return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    # change from BGR to grayscale instead if flag is 0\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "'''\n",
    "This function receives an array of arbitrary real numbers (that could include even negative values),\n",
    "and returns an 'image' in the range [0,1].\n",
    "flag_GLOBAL allows the user to normalize the whole image (including all channels) or to normalize\n",
    "each channel/band independently.\n",
    "'''\n",
    "\n",
    "\n",
    "def rangeDisplay01(im, flag_GLOBAL=True):\n",
    "    im = im.astype(float)\n",
    "    if flag_GLOBAL:\n",
    "        im = (im - im.min()) / (im.max() - im.min())\n",
    "    else:\n",
    "        # bands normalization\n",
    "        for band in range(im.shape[2]):\n",
    "            im[:, :, band] = (im[:, :, band] - im[:, :, band].min()) / (im[:, :, band].max() - im[:, :, band].min())\n",
    "            # Note: remember that, for plt.imshow with RGB data, the valid range is [0..1] for floats and [0..255] for integers.\n",
    "    return im\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Función para mostrar imágenes en pantalla en color y blanco negro. Permite realizar\n",
    "aumento sobre las mismas para apreciar un mayor detalle.\n",
    "\n",
    "Entrada:\n",
    "    im: imagen leída en formato ndarray\n",
    "    title: nombre que recibe el marco en pantalla\n",
    "    factor: factor de aumento de la image, \"zoom\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def displayIm(im, title='Result', factor=2):\n",
    "    # First normalize range\n",
    "    max = np.max(im)\n",
    "    min = np.min(im)\n",
    "    if min < 0 or max > 255:\n",
    "        im = rangeDisplay01(im, flag_GLOBAL=True)\n",
    "    if len(im.shape) == 3:\n",
    "        # im es tribanda\n",
    "        plt.imshow(im, cmap='jet')\n",
    "    else:\n",
    "        # im es monobanda\n",
    "        plt.imshow(im, cmap='gray')\n",
    "    figure_size = plt.gcf().get_size_inches()\n",
    "    plt.gcf().set_size_inches(factor * figure_size)\n",
    "    plt.title(title)\n",
    "    plt.xticks([]), plt.yticks([])  # eliminamos numeración\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:33:45.606919Z",
     "start_time": "2024-03-30T13:33:45.598170Z"
    }
   },
   "id": "3fc4a96b5083fb1e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# En estas variables, se acumularán las clases de cada dataset para matener notación común\n",
    "\n",
    "global_y = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:33:45.611771Z",
     "start_time": "2024-03-30T13:33:45.608046Z"
    }
   },
   "id": "78ce4e6ebfd054bf",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ISIC Skin Dataset\n",
    "\n",
    "Se trata del dataset de mayor tamaño del conjunto. Contiene 31 clases identificadas, tanto de lesiones benignas y malignas de la piel. En total, se dispone de 53738, las cuales ya han sido filtradas para asegurarse de que no exista redundancia por las herramientas online de la galería ISIC: https://gallery.isic-archive.com/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1408e12cf23be0cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extractISIC(path: str):\n",
    "    # Obtener una lista de todos los archivos ZIP en la carpeta especificada\n",
    "    archivos_zip = [f for f in os.listdir(path) if f.lower().endswith('.zip')]\n",
    "\n",
    "    # Iterar sobre cada archivo ZIP\n",
    "    for archivo_zip in archivos_zip:\n",
    "        ruta_archivo_zip = os.path.join(path, archivo_zip)\n",
    "        carpeta_salida = os.path.splitext(ruta_archivo_zip)[0]  # Eliminar la extensión .zip\n",
    "\n",
    "        # Comprobar si la carpeta de salida ya existe\n",
    "        if not os.path.exists(carpeta_salida):\n",
    "            os.makedirs(carpeta_salida)  # Crear la carpeta de salida\n",
    "\n",
    "            # Extraer el contenido del archivo ZIP en la carpeta de salida\n",
    "            with zipfile.ZipFile(ruta_archivo_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(carpeta_salida)\n",
    "            print(f\"Extraído {archivo_zip} en {carpeta_salida}\")\n",
    "        else:\n",
    "            print(f\"Omitido {archivo_zip}. {carpeta_salida} ya existe.\")\n",
    "\n",
    "\n",
    "def listar_clases(path):\n",
    "    # Obtener una lista de todas las carpetas en el path\n",
    "    return [nombre for nombre in os.listdir(path) if os.path.isdir(os.path.join(path, nombre))]\n",
    "\n",
    "\n",
    "def definir_etiquetas_ISIC():\n",
    "    clases = listar_clases(ISIC_PATH)\n",
    "    print(clases)\n",
    "    return [clase.replace(\" \", \"_\").lower() for clase in clases]\n",
    "\n",
    "\n",
    "def crear_csv(path, clases, nombre_dataset):\n",
    "    # Inicializa una lista vacía para almacenar la información de los archivos\n",
    "    info_archivos = []\n",
    "    i = 0\n",
    "\n",
    "    # Itera sobre cada carpeta en la carpeta raíz\n",
    "    for nombre_carpeta in os.listdir(path):\n",
    "        ruta_carpeta = os.path.join(path, nombre_carpeta)\n",
    "\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "\n",
    "            # Itera sobre cada archivo en la carpeta\n",
    "            for nombre_archivo in os.listdir(ruta_carpeta):\n",
    "                ruta_archivo = os.path.join(ruta_carpeta, nombre_archivo)\n",
    "                if os.path.isfile(\n",
    "                        ruta_archivo) and nombre_archivo != \"metadata.csv\" and nombre_archivo != \"attribution.txt\":\n",
    "                    # Agrega la información del archivo a la lista\n",
    "                    info_archivos.append((nombre_archivo, ruta_archivo, clases[i], nombre_dataset))\n",
    "            i += 1\n",
    "\n",
    "    # Define la ruta del archivo CSV\n",
    "    ruta_archivo_csv = \"preprocessedData.csv\"\n",
    "\n",
    "    # Escribe la información de los archivos en el archivo CSV\n",
    "    with open(ruta_archivo_csv, \"w\", newline=\"\") as archivo_csv:\n",
    "        escritor_csv = csv.writer(archivo_csv)\n",
    "        escritor_csv.writerow([\"image\", \"dir\", \"class\", \"dataset\"])  # Escribe la cabecera\n",
    "        escritor_csv.writerows(info_archivos)  # Escribe la información de los archivos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:33:45.623197Z",
     "start_time": "2024-03-30T13:33:45.613862Z"
    }
   },
   "id": "d41e691f663fb6eb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "[]\n",
      "C:\\Users\\Cris1\\Documents\\TFG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Accedemos al directorio de ISIC\n",
    "print(os.getcwd())\n",
    "\n",
    "# Extraemos cada zip, en caso de que no exista\n",
    "#extractISIC(ISIC_PATH)\n",
    "\n",
    "# Tomamos los nombres de cada imagen, y le asociamos su etiqueta manualmente\n",
    "print(os.getcwd())\n",
    "\n",
    "isic_y = definir_etiquetas_ISIC()\n",
    "global_y = deepcopy(isic_y)\n",
    "\n",
    "# Creamos CSV\n",
    "crear_csv(ISIC_PATH, isic_y, \"ISIC\")\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:33:45.632386Z",
     "start_time": "2024-03-30T13:33:45.624212Z"
    }
   },
   "id": "30e522877d106585",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ASAN Dataset\n",
    "\n",
    "Este dataset es el segundo de mayor tamaño recogido. En total, dispone de 17,125 imágenes de 12 clases distintas. Muchas de estas clases tratan la misma enfermedad, pero distinguen si se ha realizado biopsia o no para verificarlo (aunque todos los resultados han sido confirmados posteriormente tras estudiar su evolución).\n",
    "\n",
    "La dificultad de este conjunto de datos se debe al formato de almacenaje escogido: todas las imágenes fueron guardadas en estructura de rejilla, provocando la existencia de cientos de imágenes en un mismo espacio separado por bordes blancos. Por tanto, habrá que realizar una etapa de preprocesado más profundo que ISIC para dividir correctamente la imagen y remover los bordes blancos para evitar sesgos en los resultados del modelo final.\n",
    "\n",
    "El código se divide en dos fases: una primera fase de separación, y la segunda de barajado, donde uniremos el conjunto de entrenamiento y test dividido anteriormente, ya que la proporción elegida para test fue de un apenas 10%, y no se conoce el grado de aleatoriedad del criterio de seperación elegido."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c775bc455084f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grosor_borde = 8  # Constante del borde a eliminar (px)\n",
    "carpeta_dest = \"thumbnails\"\n",
    "\n",
    "\n",
    "# Recortado\n",
    "def recortarImagenesASAN(path):\n",
    "    os.chdir(path)\n",
    "\n",
    "    if not os.path.exists(carpeta_dest):\n",
    "        os.makedirs(carpeta_dest)\n",
    "\n",
    "    files = [f for f in pathlib.Path().iterdir() if f.is_file()][1:]\n",
    "\n",
    "    names = []\n",
    "    diss_class = []\n",
    "    for f in files:\n",
    "        name = str(f)[20:-4]\n",
    "        if \".png\" in str(f):\n",
    "            image = cv2.imread(str(f), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "            gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "            contours, _ = cv2.findContours(gradient, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            i = 0\n",
    "            for cnt in contours:\n",
    "                (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 0))\n",
    "                box_image = image[y: y + h, x: x + w]\n",
    "\n",
    "                # Recorta la imagen para eliminar el borde\n",
    "                img_sin_borde = box_image[grosor_borde:-grosor_borde, grosor_borde:-grosor_borde]\n",
    "                cv2.imwrite(f\"thumbnails/{name}_{i}.png\", img_sin_borde)\n",
    "                i += 1\n",
    "\n",
    "                names.append(f\"{name}_{i}.png\")\n",
    "                i += 1\n",
    "                diss_class.append(name)\n",
    "\n",
    "    os.chdir(\"../../../\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:45:41.677972Z",
     "start_time": "2024-03-30T13:45:41.670562Z"
    }
   },
   "id": "b071de6f6b7f7806",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "im_test.ipynb\n",
      "L#12dx#test-asan10#biopsy#ak.png\n",
      "L#12dx#test-asan10#biopsy#ak.png\n",
      "L#12dx#test-asan10#biopsy#bcc.png\n",
      "L#12dx#test-asan10#biopsy#bcc.png\n",
      "L#12dx#test-asan10#biopsy#dermatofibroma.png\n",
      "L#12dx#test-asan10#biopsy#dermatofibroma.png\n",
      "L#12dx#test-asan10#biopsy#hemangioma.png\n",
      "L#12dx#test-asan10#biopsy#hemangioma.png\n",
      "L#12dx#test-asan10#biopsy#intraepithelial carcinoma.png\n",
      "L#12dx#test-asan10#biopsy#intraepithelial carcinoma.png\n",
      "L#12dx#test-asan10#biopsy#lentigo.png\n",
      "L#12dx#test-asan10#biopsy#lentigo.png\n",
      "L#12dx#test-asan10#biopsy#melanoma.png\n",
      "L#12dx#test-asan10#biopsy#melanoma.png\n",
      "L#12dx#test-asan10#biopsy#nevus.png\n",
      "L#12dx#test-asan10#biopsy#nevus.png\n",
      "L#12dx#test-asan10#biopsy#pyogenic granuloma.png\n",
      "L#12dx#test-asan10#biopsy#pyogenic granuloma.png\n",
      "L#12dx#test-asan10#biopsy#scc.png\n",
      "L#12dx#test-asan10#biopsy#scc.png\n",
      "L#12dx#test-asan10#biopsy#sebk.png\n",
      "L#12dx#test-asan10#biopsy#sebk.png\n",
      "L#12dx#test-asan10#biopsy#wart.png\n",
      "L#12dx#test-asan10#biopsy#wart.png\n",
      "L#12dx#hallym#back bcc.png\n",
      "L#12dx#hallym#back bcc.png\n",
      "L#12dx#hallym#hallym bcc.png\n",
      "L#12dx#hallym#hallym bcc.png\n"
     ]
    }
   ],
   "source": [
    "# Ejecutamos la separación del conjunto de train\n",
    "print(os.getcwd())\n",
    "\n",
    "recortarImagenesASAN(ASAN_PATH + \"/train_dataset\")\n",
    "recortarImagenesASAN(ASAN_PATH + \"/test_dataset\")\n",
    "recortarImagenesASAN(ASAN_PATH + \"/Hallym_dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:47:10.867419Z",
     "start_time": "2024-03-30T13:47:08.687823Z"
    }
   },
   "id": "a0f2105d9f689dbd",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
