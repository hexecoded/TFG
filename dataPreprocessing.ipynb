{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocesado de datos\n",
    "\n",
    "El preprocesado de datos es una fase indispensable para el correndo aprendizaje por partes de los algoritmos de Deeplearning. Se ha demostrado empíricamente que una correcta preparación y normalización de los datos permiten hallar soluciones más cercanas a la optima que con datos no procesados.\n",
    "\n",
    "Es importante tener en cuenta que no existe una metodología de preprocesado única, y que es necesario adaptarse al tipo de dato que estamos tratando. Para este proyecto, además, existe una dificultad adicional, y es la existencia de diferentes procedencias para los datos, pues en total se dispone de 5 datasets distintos, cada uno recopilado con diferentes metodologías e instrumentación. Por tanto, será clave adaptarse a cada uno de los destinos, y realizar la partición final de forma estratificada para evitar sesgos que perturben el resutado.\n",
    "\n",
    "Más adelante, profundizaremos en este aspecto, pero en primer lugar, debemos leer cada uno de los conjuntos de datos disponibles, y examinar de cuántos elementos disponemos en cada uno, para establecer la proporción de entrenamiento-test oportuna."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785e9721acd8fc9b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Librerías utilizadas por el script\n",
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "import csv\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:04.226398Z",
     "start_time": "2024-03-30T15:59:04.221949Z"
    }
   },
   "id": "afde0d5870507596",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset disponibles\n",
    "\n",
    "Haciendo uso de los recursos disponibles públicamente, se han tomado los siguientes datasets para realizar el experimento:\n",
    "- ISIC: es el mayor conjuntos de datos cutáneos disponible en abierto, y contiene imágenes de todo tipo de pieles y procedencias, pero con especial énfasis en las personas de origen europeo y americano.\n",
    "- ASAN: Conjunto de datos provenientes del hospital con este mismo nombre, con lesiones en personas de origen asiático.\n",
    "- PAD UFES 20: conjunto de datos de lesiones variadas de pacientes latinoamericanos.\n",
    "- PH2: banco de datos de pacientes brasileños con lesiones potencialmente cancerosas.\n",
    "- Severance: base de datos con lesiones cutáneas en población asiática, con contenido tanto benigno como cancerígeno.\n",
    "\n",
    "Para unificar la notación de los datos, se creará un código para la notación de cada una de las clases que permitan un procesamiento común de todos los datos sin depender del origen de este. Para ello, se creará un nuevo archivo .csv donde se anotará el path de la imagen, su clase asociada, y el tipo general de la misma (beningna o maligna). La metainformación asociada, de momento, quedará relegado a un segundo plano hasta el estudio estadístico de los datos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f2cc21e905cd6fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Directorios de cada dataset\n",
    "\n",
    "ISIC_PATH = \"datasets/ISIC\"\n",
    "ASAN_PATH = \"datasets/Asan\"\n",
    "PAD_UFES_PATH = \"datasets/PAD_UFES_20\"\n",
    "PH2_PATH = \"datasets/PH2\"\n",
    "SEVERANCE = \"datasets/Severance\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:04.236406Z",
     "start_time": "2024-03-30T15:59:04.227408Z"
    }
   },
   "id": "8181ac991513a205",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Funciones comunes para la lectura y muestra de datos\n",
    "\n",
    "'''\n",
    "This function receives a string with the filename of the image to read,\n",
    "and a flag indicating if we want to read it in color/RGB (flagColor=1) or gray level (flagColor=0)\n",
    "\n",
    "Example of use:\n",
    "im1=readIm(get_image('apple.jpg'),0)\n",
    "'''\n",
    "\n",
    "\n",
    "def readIm(filename, flagColor=1):\n",
    "    # cv2 reads BGR format\n",
    "    im = cv2.imread(filename)\n",
    "    # change to  RGB and return the image\n",
    "    if (flagColor):\n",
    "        return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    # change from BGR to grayscale instead if flag is 0\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "'''\n",
    "This function receives an array of arbitrary real numbers (that could include even negative values),\n",
    "and returns an 'image' in the range [0,1].\n",
    "flag_GLOBAL allows the user to normalize the whole image (including all channels) or to normalize\n",
    "each channel/band independently.\n",
    "'''\n",
    "\n",
    "\n",
    "def rangeDisplay01(im, flag_GLOBAL=True):\n",
    "    im = im.astype(float)\n",
    "    if flag_GLOBAL:\n",
    "        im = (im - im.min()) / (im.max() - im.min())\n",
    "    else:\n",
    "        # bands normalization\n",
    "        for band in range(im.shape[2]):\n",
    "            im[:, :, band] = (im[:, :, band] - im[:, :, band].min()) / (im[:, :, band].max() - im[:, :, band].min())\n",
    "            # Note: remember that, for plt.imshow with RGB data, the valid range is [0..1] for floats and [0..255] for integers.\n",
    "    return im\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Función para mostrar imágenes en pantalla en color y blanco negro. Permite realizar\n",
    "aumento sobre las mismas para apreciar un mayor detalle.\n",
    "\n",
    "Entrada:\n",
    "    im: imagen leída en formato ndarray\n",
    "    title: nombre que recibe el marco en pantalla\n",
    "    factor: factor de aumento de la image, \"zoom\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def displayIm(im, title='Result', factor=2):\n",
    "    # First normalize range\n",
    "    max = np.max(im)\n",
    "    min = np.min(im)\n",
    "    if min < 0 or max > 255:\n",
    "        im = rangeDisplay01(im, flag_GLOBAL=True)\n",
    "    if len(im.shape) == 3:\n",
    "        # im es tribanda\n",
    "        plt.imshow(im, cmap='jet')\n",
    "    else:\n",
    "        # im es monobanda\n",
    "        plt.imshow(im, cmap='gray')\n",
    "    figure_size = plt.gcf().get_size_inches()\n",
    "    plt.gcf().set_size_inches(factor * figure_size)\n",
    "    plt.title(title)\n",
    "    plt.xticks([]), plt.yticks([])  # eliminamos numeración\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:04.247129Z",
     "start_time": "2024-03-30T15:59:04.237414Z"
    }
   },
   "id": "3fc4a96b5083fb1e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# En estas variables, se acumularán las clases de cada dataset para matener notación común\n",
    "global_y = set()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:04.252088Z",
     "start_time": "2024-03-30T15:59:04.248164Z"
    }
   },
   "id": "78ce4e6ebfd054bf",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ISIC Skin Dataset\n",
    "\n",
    "Se trata del dataset de mayor tamaño del conjunto. Contiene 31 clases identificadas, tanto de lesiones benignas y malignas de la piel. En total, se dispone de 53738, las cuales ya han sido filtradas para asegurarse de que no exista redundancia por las herramientas online de la galería ISIC: https://gallery.isic-archive.com/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1408e12cf23be0cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extractISIC(path: str):\n",
    "    # Obtener una lista de todos los archivos ZIP en la carpeta especificada\n",
    "    archivos_zip = [f for f in os.listdir(path) if f.lower().endswith('.zip')]\n",
    "\n",
    "    # Iterar sobre cada archivo ZIP\n",
    "    for archivo_zip in archivos_zip:\n",
    "        ruta_archivo_zip = os.path.join(path, archivo_zip)\n",
    "        carpeta_salida = os.path.splitext(ruta_archivo_zip)[0]  # Eliminar la extensión .zip\n",
    "\n",
    "        # Comprobar si la carpeta de salida ya existe\n",
    "        if not os.path.exists(carpeta_salida):\n",
    "            os.makedirs(carpeta_salida)  # Crear la carpeta de salida\n",
    "\n",
    "            # Extraer el contenido del archivo ZIP en la carpeta de salida\n",
    "            with zipfile.ZipFile(ruta_archivo_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(carpeta_salida)\n",
    "            print(f\"Extraído {archivo_zip} en {carpeta_salida}\")\n",
    "        else:\n",
    "            print(f\"Omitido {archivo_zip}. {carpeta_salida} ya existe.\")\n",
    "\n",
    "\n",
    "def listar_clases(path):\n",
    "    # Obtener una lista de todas las carpetas en el path\n",
    "    return [nombre for nombre in os.listdir(path) if os.path.isdir(os.path.join(path, nombre))]\n",
    "\n",
    "\n",
    "def definir_etiquetas(path):\n",
    "    clases = listar_clases(path)\n",
    "    print(clases)\n",
    "    return [clase.replace(\" \", \"_\").lower() for clase in clases]\n",
    "\n",
    "\n",
    "def crear_csv(path, clases, nombre_dataset):\n",
    "    # Inicializa una lista vacía para almacenar la información de los archivos\n",
    "    info_archivos = []\n",
    "    i = 0\n",
    "\n",
    "    # Itera sobre cada carpeta en la carpeta raíz\n",
    "    for nombre_carpeta in os.listdir(path):\n",
    "        ruta_carpeta = os.path.join(path, nombre_carpeta)\n",
    "\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "\n",
    "            # Itera sobre cada archivo en la carpeta\n",
    "            for nombre_archivo in os.listdir(ruta_carpeta):\n",
    "                ruta_archivo = os.path.join(ruta_carpeta, nombre_archivo)\n",
    "                if os.path.isfile(\n",
    "                        ruta_archivo) and nombre_archivo != \"metadata.csv\" and nombre_archivo != \"attribution.txt\":\n",
    "                    # Agrega la información del archivo a la lista\n",
    "                    info_archivos.append((nombre_archivo, ruta_archivo, clases[i], nombre_dataset))\n",
    "            i += 1\n",
    "\n",
    "    # Define la ruta del archivo CSV\n",
    "    ruta_archivo_csv = \"preprocessedData.csv\"\n",
    "\n",
    "    # Escribe la información de los archivos en el archivo CSV\n",
    "    with open(ruta_archivo_csv, \"w\", newline=\"\") as archivo_csv:\n",
    "        escritor_csv = csv.writer(archivo_csv)\n",
    "        escritor_csv.writerow([\"image\", \"dir\", \"class\", \"dataset\"])  # Escribe la cabecera\n",
    "        escritor_csv.writerows(info_archivos)  # Escribe la información de los archivos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:04.264314Z",
     "start_time": "2024-03-30T15:59:04.254135Z"
    }
   },
   "id": "d41e691f663fb6eb",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "Omitido Acrochordon.zip. datasets/ISIC\\Acrochordon ya existe.\n",
      "Omitido Acticnic keratosis.zip. datasets/ISIC\\Acticnic keratosis ya existe.\n",
      "Omitido AIMP.zip. datasets/ISIC\\AIMP ya existe.\n",
      "Omitido Angiofibroma or fibreus papule.zip. datasets/ISIC\\Angiofibroma or fibreus papule ya existe.\n",
      "Omitido Angiokeratoma.zip. datasets/ISIC\\Angiokeratoma ya existe.\n",
      "Omitido Angioma.zip. datasets/ISIC\\Angioma ya existe.\n",
      "Omitido Atypical melanocytic proliferation.zip. datasets/ISIC\\Atypical melanocytic proliferation ya existe.\n",
      "Omitido Atypical spitz tumor.zip. datasets/ISIC\\Atypical spitz tumor ya existe.\n",
      "Omitido Basal Cell Carcinoma.zip. datasets/ISIC\\Basal Cell Carcinoma ya existe.\n",
      "Omitido Cafe au lait macule.zip. datasets/ISIC\\Cafe au lait macule ya existe.\n",
      "Omitido Clear cell acarthoma.zip. datasets/ISIC\\Clear cell acarthoma ya existe.\n",
      "Omitido Dermatofibroma.zip. datasets/ISIC\\Dermatofibroma ya existe.\n",
      "Omitido Lentigo NOS.zip. datasets/ISIC\\Lentigo NOS ya existe.\n",
      "Omitido Lentigo Simplex.zip. datasets/ISIC\\Lentigo Simplex ya existe.\n",
      "Omitido Lichenoid keratosis.zip. datasets/ISIC\\Lichenoid keratosis ya existe.\n",
      "Omitido Melanoma metastasis.zip. datasets/ISIC\\Melanoma metastasis ya existe.\n",
      "Omitido Melanoma.zip. datasets/ISIC\\Melanoma ya existe.\n",
      "Omitido Mucosal melanosis.zip. datasets/ISIC\\Mucosal melanosis ya existe.\n",
      "Omitido Neurofibroma.zip. datasets/ISIC\\Neurofibroma ya existe.\n",
      "Omitido Nevus spilus.zip. datasets/ISIC\\Nevus spilus ya existe.\n",
      "Omitido Nevus.zip. datasets/ISIC\\Nevus ya existe.\n",
      "Omitido Pigmented benign keratosis.zip. datasets/ISIC\\Pigmented benign keratosis ya existe.\n",
      "Omitido Pyogenic granuloma.zip. datasets/ISIC\\Pyogenic granuloma ya existe.\n",
      "Omitido Scar.zip. datasets/ISIC\\Scar ya existe.\n",
      "Omitido Sebaceus anedoma.zip. datasets/ISIC\\Sebaceus anedoma ya existe.\n",
      "Omitido Sebaceus hyperplasia.zip. datasets/ISIC\\Sebaceus hyperplasia ya existe.\n",
      "Omitido Seborreic Keratosis.zip. datasets/ISIC\\Seborreic Keratosis ya existe.\n",
      "Omitido Solar lentigo.zip. datasets/ISIC\\Solar lentigo ya existe.\n",
      "Omitido Squamous cell carcinoma.zip. datasets/ISIC\\Squamous cell carcinoma ya existe.\n",
      "Omitido Vascular Lesion.zip. datasets/ISIC\\Vascular Lesion ya existe.\n",
      "Omitido Verruca.zip. datasets/ISIC\\Verruca ya existe.\n",
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "['Acrochordon', 'Acticnic keratosis', 'AIMP', 'Angiofibroma or fibreus papule', 'Angiokeratoma', 'Angioma', 'Atypical melanocytic proliferation', 'Atypical spitz tumor', 'Basal Cell Carcinoma', 'Cafe au lait macule', 'Clear cell acarthoma', 'Dermatofibroma', 'Lentigo NOS', 'Lentigo Simplex', 'Lichenoid keratosis', 'Melanoma', 'Melanoma metastasis', 'Mucosal melanosis', 'Neurofibroma', 'Nevus', 'Nevus spilus', 'Pigmented benign keratosis', 'Pyogenic granuloma', 'Scar', 'Sebaceus anedoma', 'Sebaceus hyperplasia', 'Seborreic Keratosis', 'Solar lentigo', 'Squamous cell carcinoma', 'Vascular Lesion', 'Verruca']\n",
      "C:\\Users\\Cris1\\Documents\\TFG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Accedemos al directorio de ISIC\n",
    "print(os.getcwd())\n",
    "\n",
    "# Extraemos cada zip, en caso de que no exista\n",
    "extractISIC(ISIC_PATH)\n",
    "\n",
    "# Tomamos los nombres de cada imagen, y le asociamos su etiqueta manualmente\n",
    "print(os.getcwd())\n",
    "\n",
    "isic_y = definir_etiquetas(ISIC_PATH)\n",
    "global_y = global_y.union(set(isic_y))\n",
    "\n",
    "# Creamos CSV\n",
    "crear_csv(ISIC_PATH, isic_y, \"ISIC\")\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:06.703286Z",
     "start_time": "2024-03-30T15:59:04.265320Z"
    }
   },
   "id": "30e522877d106585",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ASAN Dataset\n",
    "\n",
    "Este dataset es el segundo de mayor tamaño recogido. En total, dispone de 17,125 imágenes de 12 clases distintas. Muchas de estas clases tratan la misma enfermedad, pero distinguen si se ha realizado biopsia o no para verificarlo (aunque todos los resultados han sido confirmados posteriormente tras estudiar su evolución).\n",
    "\n",
    "La dificultad de este conjunto de datos se debe al formato de almacenaje escogido: todas las imágenes fueron guardadas en estructura de rejilla, provocando la existencia de cientos de imágenes en un mismo espacio separado por bordes blancos. Por tanto, habrá que realizar una etapa de preprocesado más profundo que ISIC para dividir correctamente la imagen y remover los bordes blancos para evitar sesgos en los resultados del modelo final.\n",
    "\n",
    "El código se divide en dos fases: una primera fase de separación, y la segunda de barajado, donde uniremos el conjunto de entrenamiento y test dividido anteriormente, ya que la proporción elegida para test fue de un apenas 10%, y no se conoce el grado de aleatoriedad del criterio de seperación elegido."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c775bc455084f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grosor_borde = 8  # Constante del borde a eliminar (px)\n",
    "\n",
    "\n",
    "# Recortado\n",
    "def recortarImagenesASAN(path, i):\n",
    "    os.chdir(path)\n",
    "\n",
    "    files = [f for f in pathlib.Path().iterdir() if f.is_file()][1:]\n",
    "\n",
    "    names = []\n",
    "    diss_class = []\n",
    "\n",
    "    for f in files:\n",
    "        name = str(f)[str(f).rfind(\"#\") + 1:-4]\n",
    "\n",
    "        if \".png\" in str(f):\n",
    "            print(\"Procesando \", name)\n",
    "            if not os.path.exists(name):\n",
    "                os.makedirs(name)\n",
    "\n",
    "            image = cv2.imread(str(f), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "            gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "            contours, _ = cv2.findContours(gradient, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for cnt in contours:\n",
    "                (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 0))\n",
    "                box_image = image[y: y + h, x: x + w]\n",
    "\n",
    "                # Recorta la imagen para eliminar el borde\n",
    "                img_sin_borde = box_image[grosor_borde:-grosor_borde, grosor_borde:-grosor_borde]\n",
    "                cv2.imwrite(f\"{name}/ASAN_{i}.png\", img_sin_borde)\n",
    "\n",
    "                names.append(f\"ASAN_{i}.png\")\n",
    "                diss_class.append(name)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    os.chdir(\"../../../\")\n",
    "\n",
    "    return i"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:06.713243Z",
     "start_time": "2024-03-30T15:59:06.705297Z"
    }
   },
   "id": "b071de6f6b7f7806",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def aniadir_csv(path, clases, nombre_dataset):\n",
    "    # Inicializa una lista vacía para almacenar la información de los archivos\n",
    "    info_archivos = []\n",
    "    i = 0\n",
    "\n",
    "    # Itera sobre cada carpeta en la carpeta raíz\n",
    "    for nombre_carpeta in os.listdir(path):\n",
    "        ruta_carpeta = os.path.join(path, nombre_carpeta)\n",
    "\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "\n",
    "            # Itera sobre cada archivo en la carpeta\n",
    "            for nombre_archivo in os.listdir(ruta_carpeta):\n",
    "                ruta_archivo = os.path.join(ruta_carpeta, nombre_archivo)\n",
    "                if os.path.isfile(\n",
    "                        ruta_archivo) and nombre_archivo != \"metadata.csv\" and nombre_archivo != \"attribution.txt\":\n",
    "                    # Agrega la información del archivo a la lista\n",
    "                    info_archivos.append((nombre_archivo, ruta_archivo, clases[i], nombre_dataset))\n",
    "            i += 1\n",
    "\n",
    "    # Define la ruta del archivo CSV\n",
    "    ruta_archivo_csv = \"preprocessedData.csv\"\n",
    "\n",
    "    # Escribe la información de los archivos en el archivo CSV\n",
    "\n",
    "    with open(ruta_archivo_csv, \"a\", newline=\"\") as archivo_csv:\n",
    "        escritor_csv = csv.writer(archivo_csv)\n",
    "        escritor_csv.writerows(info_archivos)  # Escribe la información de los archivos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T15:59:06.724007Z",
     "start_time": "2024-03-30T15:59:06.714246Z"
    }
   },
   "id": "5fff6bbd0699da26",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cris1\\Documents\\TFG\n",
      "Procesando  acticnic keratosis\n",
      "Procesando  basal cell carcinoma\n",
      "Procesando  dermatofibroma\n",
      "Procesando  hemangioma\n",
      "Procesando  intraepithelial carcinoma\n",
      "Procesando  lentigo nos\n",
      "Procesando  melanoma\n",
      "Procesando  nevus\n",
      "Procesando  pyogenic granuloma\n",
      "Procesando  Seborreic Keratosis\n",
      "Procesando  Squamous cell carcinoma\n",
      "Procesando  wart\n",
      "Procesando  Acticnic keratosis\n",
      "Procesando  dermatofibroma\n",
      "Procesando  hemangioma\n",
      "Procesando  lentigo nos\n",
      "Procesando  nevus\n",
      "Procesando  pyogenic granuloma\n",
      "Procesando  Seborreic Keratosis\n",
      "Procesando  wart\n",
      "Procesando  acticnic keratosis\n",
      "Procesando  basal cell carcinoma\n",
      "Procesando  dermatofibroma\n",
      "Procesando  hemangioma\n",
      "Procesando  intraepithelial carcinoma\n",
      "Procesando  lentigo nos\n",
      "Procesando  melanoma\n",
      "Procesando  nevus\n",
      "Procesando  pyogenic granuloma\n",
      "Procesando  Seborreic Keratosis\n",
      "Procesando  Squamous cell carcinoma\n",
      "Procesando  wart\n",
      "['acticnic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'hemangioma', 'intraepithelial carcinoma', 'lentigo nos', 'melanoma', 'nevus', 'pyogenic granuloma', 'Seborreic Keratosis', 'Squamous cell carcinoma', 'wart']\n"
     ]
    }
   ],
   "source": [
    "# Ejecutamos la separación del conjunto de train\n",
    "\n",
    "i = 0  # identificador de imagen\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "i = recortarImagenesASAN(ASAN_PATH + \"/train_dataset\", i)\n",
    "i = recortarImagenesASAN(ASAN_PATH + \"/test_dataset\", i)\n",
    "\n",
    "os.mkdir(ASAN_PATH + \"/dataset\")\n",
    "\n",
    "# Fusionamos ambas carpetas\n",
    "shutil.copytree(ASAN_PATH + \"/train_dataset\", ASAN_PATH + \"/dataset\", dirs_exist_ok=True)\n",
    "shutil.copytree(ASAN_PATH + \"/test_dataset\", ASAN_PATH + \"/dataset\", dirs_exist_ok=True)\n",
    "\n",
    "# Añádimos nuevas etiquetas\n",
    "asan_y = definir_etiquetas(ASAN_PATH + \"/dataset\")\n",
    "global_y = global_y.union(set(asan_y))\n",
    "\n",
    "aniadir_csv(ASAN_PATH + \"/dataset\",asan_y,\"ASAN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:00:54.829952Z",
     "start_time": "2024-03-30T15:59:06.726018Z"
    }
   },
   "id": "a0f2105d9f689dbd",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
